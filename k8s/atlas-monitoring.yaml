# Atlas Comprehensive Monitoring and Observability Platform
# Enterprise-grade monitoring with AI-powered alerts and analytics
apiVersion: v1
kind: Namespace
metadata:
  name: atlas-monitoring
  labels:
    name: atlas-monitoring
    atlas.monitoring: 'enabled'
---
# Prometheus for Metrics Collection
apiVersion: apps/v1
kind: Deployment
metadata:
  name: atlas-prometheus
  namespace: atlas-monitoring
  labels:
    app: prometheus
    atlas.monitoring.component: metrics
spec:
  replicas: 2
  selector:
    matchLabels:
      app: prometheus
  template:
    metadata:
      labels:
        app: prometheus
    spec:
      serviceAccountName: prometheus
      containers:
        - name: prometheus
          image: prom/prometheus:latest
          args:
            - --config.file=/etc/prometheus/prometheus.yml
            - --storage.tsdb.path=/prometheus/
            - --web.console.libraries=/etc/prometheus/console_libraries
            - --web.console.templates=/etc/prometheus/consoles
            - --storage.tsdb.retention.time=15d
            - --web.enable-lifecycle
            - --web.enable-admin-api
          ports:
            - containerPort: 9090
          volumeMounts:
            - name: prometheus-config
              mountPath: /etc/prometheus
            - name: prometheus-storage
              mountPath: /prometheus
          resources:
            requests:
              memory: '1Gi'
              cpu: '500m'
            limits:
              memory: '2Gi'
              cpu: '1000m'
          livenessProbe:
            httpGet:
              path: /-/healthy
              port: 9090
            initialDelaySeconds: 30
            periodSeconds: 15
          readinessProbe:
            httpGet:
              path: /-/ready
              port: 9090
            initialDelaySeconds: 5
            periodSeconds: 5
      volumes:
        - name: prometheus-config
          configMap:
            name: atlas-prometheus-config
        - name: prometheus-storage
          persistentVolumeClaim:
            claimName: prometheus-storage
---
# Atlas Prometheus Configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: atlas-prometheus-config
  namespace: atlas-monitoring
  labels:
    atlas.monitoring: prometheus-config
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
      evaluation_interval: 15s
      external_labels:
        cluster: 'atlas-production'
        environment: 'production'

    rule_files:
      - "/etc/prometheus/rules/*.yml"

    alerting:
      alertmanagers:
        - static_configs:
            - targets:
              - atlas-alertmanager:9093

    scrape_configs:
    # Astral Turf Application Metrics
    - job_name: 'astral-turf'
      scrape_interval: 10s
      metrics_path: /metrics
      kubernetes_sd_configs:
      - role: pod
        namespaces:
          names:
          - astral-turf
      relabel_configs:
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
        action: replace
        target_label: __metrics_path__
        regex: (.+)
      - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
        action: replace
        regex: ([^:]+)(?::\d+)?;(\d+)
        replacement: $1:$2
        target_label: __address__

    # Kubernetes Cluster Metrics
    - job_name: 'kubernetes-apiservers'
      kubernetes_sd_configs:
      - role: endpoints
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
      bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      relabel_configs:
      - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
        action: keep
        regex: default;kubernetes;https

    # Node Exporter
    - job_name: 'kubernetes-nodes'
      kubernetes_sd_configs:
      - role: node
      relabel_configs:
      - action: labelmap
        regex: __meta_kubernetes_node_label_(.+)
      - target_label: __address__
        replacement: kubernetes.default.svc:443
      - source_labels: [__meta_kubernetes_node_name]
        regex: (.+)
        target_label: __metrics_path__
        replacement: /api/v1/nodes/${1}/proxy/metrics

    # cAdvisor
    - job_name: 'kubernetes-cadvisor'
      kubernetes_sd_configs:
      - role: node
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
      bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      relabel_configs:
      - action: labelmap
        regex: __meta_kubernetes_node_label_(.+)
      - target_label: __address__
        replacement: kubernetes.default.svc:443
      - source_labels: [__meta_kubernetes_node_name]
        regex: (.+)
        target_label: __metrics_path__
        replacement: /api/v1/nodes/${1}/proxy/metrics/cadvisor

    # Custom Atlas Metrics
    - job_name: 'atlas-deployment-metrics'
      scrape_interval: 30s
      static_configs:
      - targets: ['atlas-metrics-exporter:8080']
      metric_relabel_configs:
      - source_labels: [__name__]
        regex: 'atlas_.*'
        action: keep

  # Atlas Custom Alert Rules
  atlas-rules.yml: |
    groups:
    - name: atlas.deployment.rules
      interval: 30s
      rules:
      # Application Health Rules
      - alert: AtlasTacticalBoardDown
        expr: up{job="astral-turf"} == 0
        for: 1m
        labels:
          severity: critical
          team: platform
          service: astral-turf
        annotations:
          summary: "Astral Turf Tactical Board is down"
          description: "Astral Turf application has been down for more than 1 minute."
          runbook_url: "https://runbooks.atlas.io/astral-turf-down"
      
      - alert: AtlasHighErrorRate
        expr: (rate(http_requests_total{status=~"5.."}[5m]) / rate(http_requests_total[5m])) > 0.01
        for: 2m
        labels:
          severity: warning
          team: platform
          service: astral-turf
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value | humanizePercentage }} over the last 5 minutes."
          
      - alert: AtlasHighLatency
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 0.5
        for: 3m
        labels:
          severity: warning
          team: platform
          service: astral-turf
        annotations:
          summary: "High latency detected"
          description: "95th percentile latency is {{ $value }}s over the last 5 minutes."
      
      # Resource Usage Rules
      - alert: AtlasHighCPUUsage
        expr: (rate(container_cpu_usage_seconds_total{pod=~"astral-turf-.*"}[5m]) * 100) > 80
        for: 5m
        labels:
          severity: warning
          team: platform
          service: astral-turf
        annotations:
          summary: "High CPU usage"
          description: "Pod {{ $labels.pod }} CPU usage is above 80%"
      
      - alert: AtlasHighMemoryUsage
        expr: (container_memory_working_set_bytes{pod=~"astral-turf-.*"} / container_spec_memory_limit_bytes) * 100 > 85
        for: 5m
        labels:
          severity: warning
          team: platform
          service: astral-turf
        annotations:
          summary: "High memory usage"
          description: "Pod {{ $labels.pod }} memory usage is above 85%"
      
      # Deployment Rules
      - alert: AtlasDeploymentFailed
        expr: kube_deployment_status_replicas_unavailable{deployment=~"astral-turf-.*"} > 0
        for: 10m
        labels:
          severity: critical
          team: platform
          service: astral-turf
        annotations:
          summary: "Deployment has unavailable replicas"
          description: "Deployment {{ $labels.deployment }} has {{ $value }} unavailable replicas"
      
      # Database Rules
      - alert: AtlasDatabaseConnectionHigh
        expr: pg_stat_activity_count > 80
        for: 5m
        labels:
          severity: warning
          team: platform
          service: database
        annotations:
          summary: "High database connections"
          description: "Database has {{ $value }} active connections"
      
      # Custom Business Logic Rules
      - alert: AtlasTacticalBoardUsageSpike
        expr: increase(tactical_board_sessions_total[5m]) > 1000
        for: 2m
        labels:
          severity: info
          team: product
          service: astral-turf
        annotations:
          summary: "Tactical board usage spike detected"
          description: "{{ $value }} new tactical board sessions in the last 5 minutes"
---
# Grafana for Visualization
apiVersion: apps/v1
kind: Deployment
metadata:
  name: atlas-grafana
  namespace: atlas-monitoring
  labels:
    app: grafana
    atlas.monitoring.component: visualization
spec:
  replicas: 1
  selector:
    matchLabels:
      app: grafana
  template:
    metadata:
      labels:
        app: grafana
    spec:
      containers:
        - name: grafana
          image: grafana/grafana:latest
          ports:
            - containerPort: 3000
          env:
            - name: GF_SECURITY_ADMIN_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: grafana-secrets
                  key: admin-password
            - name: GF_INSTALL_PLUGINS
              value: 'grafana-kubernetes-app,grafana-worldmap-panel,grafana-piechart-panel'
          volumeMounts:
            - name: grafana-storage
              mountPath: /var/lib/grafana
            - name: grafana-config
              mountPath: /etc/grafana/provisioning
          resources:
            requests:
              memory: '256Mi'
              cpu: '100m'
            limits:
              memory: '512Mi'
              cpu: '500m'
          livenessProbe:
            httpGet:
              path: /api/health
              port: 3000
            initialDelaySeconds: 30
            periodSeconds: 10
          readinessProbe:
            httpGet:
              path: /api/health
              port: 3000
            initialDelaySeconds: 5
            periodSeconds: 5
      volumes:
        - name: grafana-storage
          persistentVolumeClaim:
            claimName: grafana-storage
        - name: grafana-config
          configMap:
            name: atlas-grafana-config
---
# Atlas Grafana Configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: atlas-grafana-config
  namespace: atlas-monitoring
  labels:
    atlas.monitoring: grafana-config
data:
  datasources.yml: |
    apiVersion: 1
    datasources:
    - name: Atlas Prometheus
      type: prometheus
      access: proxy
      url: http://atlas-prometheus:9090
      isDefault: true
      editable: true
    - name: Atlas Loki
      type: loki
      access: proxy
      url: http://atlas-loki:3100
      editable: true
    - name: Atlas Jaeger
      type: jaeger
      access: proxy
      url: http://atlas-jaeger:16686
      editable: true

  dashboards.yml: |
    apiVersion: 1
    providers:
    - name: 'Atlas Dashboards'
      orgId: 1
      folder: 'Atlas'
      type: file
      disableDeletion: false
      updateIntervalSeconds: 30
      allowUiUpdates: true
      options:
        path: /etc/grafana/provisioning/dashboards
---
# AlertManager for Alerting
apiVersion: apps/v1
kind: Deployment
metadata:
  name: atlas-alertmanager
  namespace: atlas-monitoring
  labels:
    app: alertmanager
    atlas.monitoring.component: alerting
spec:
  replicas: 2
  selector:
    matchLabels:
      app: alertmanager
  template:
    metadata:
      labels:
        app: alertmanager
    spec:
      containers:
        - name: alertmanager
          image: prom/alertmanager:latest
          args:
            - --config.file=/etc/alertmanager/config.yml
            - --storage.path=/alertmanager
            - --data.retention=120h
            - --cluster.listen-address=0.0.0.0:9094
            - --cluster.peer=atlas-alertmanager-0.atlas-alertmanager:9094
            - --cluster.peer=atlas-alertmanager-1.atlas-alertmanager:9094
          ports:
            - containerPort: 9093
            - containerPort: 9094
          volumeMounts:
            - name: alertmanager-config
              mountPath: /etc/alertmanager
            - name: alertmanager-storage
              mountPath: /alertmanager
          resources:
            requests:
              memory: '128Mi'
              cpu: '50m'
            limits:
              memory: '256Mi'
              cpu: '200m'
          livenessProbe:
            httpGet:
              path: /-/healthy
              port: 9093
            initialDelaySeconds: 30
            periodSeconds: 10
          readinessProbe:
            httpGet:
              path: /-/ready
              port: 9093
            initialDelaySeconds: 5
            periodSeconds: 5
      volumes:
        - name: alertmanager-config
          configMap:
            name: atlas-alertmanager-config
        - name: alertmanager-storage
          persistentVolumeClaim:
            claimName: alertmanager-storage
---
# Atlas AlertManager Configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: atlas-alertmanager-config
  namespace: atlas-monitoring
  labels:
    atlas.monitoring: alertmanager-config
data:
  config.yml: |
    global:
      smtp_smarthost: 'smtp.gmail.com:587'
      smtp_from: 'alerts@astralturf.com'
      smtp_auth_username: 'alerts@astralturf.com'
      smtp_auth_password: '${SMTP_PASSWORD}'

    route:
      group_by: ['alertname', 'service', 'severity']
      group_wait: 10s
      group_interval: 10s
      repeat_interval: 1h
      receiver: 'atlas-default'
      routes:
      - match:
          severity: critical
        receiver: 'atlas-critical'
        group_wait: 0s
        repeat_interval: 5m
      - match:
          severity: warning
        receiver: 'atlas-warning'
        repeat_interval: 30m
      - match:
          team: platform
        receiver: 'atlas-platform-team'
      - match:
          team: product
        receiver: 'atlas-product-team'

    receivers:
    - name: 'atlas-default'
      email_configs:
      - to: 'devops@astralturf.com'
        subject: '[Atlas] Alert: {{ .GroupLabels.alertname }}'
        body: |
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          Service: {{ .Labels.service }}
          Severity: {{ .Labels.severity }}
          {{ end }}

    - name: 'atlas-critical'
      email_configs:
      - to: 'oncall@astralturf.com'
        subject: '[Atlas CRITICAL] {{ .GroupLabels.alertname }}'
        body: |
          🚨 CRITICAL ALERT 🚨
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          Service: {{ .Labels.service }}
          Runbook: {{ .Annotations.runbook_url }}
          {{ end }}
      slack_configs:
      - api_url: '${SLACK_WEBHOOK_URL}'
        channel: '#alerts'
        title: '🚨 Critical Alert: {{ .GroupLabels.alertname }}'
        text: |
          {{ range .Alerts }}
          *Service:* {{ .Labels.service }}
          *Summary:* {{ .Annotations.summary }}
          *Description:* {{ .Annotations.description }}
          {{ if .Annotations.runbook_url }}*Runbook:* {{ .Annotations.runbook_url }}{{ end }}
          {{ end }}
      pagerduty_configs:
      - routing_key: '${PAGERDUTY_INTEGRATION_KEY}'
        severity: 'critical'
        description: '{{ .GroupLabels.alertname }}'

    - name: 'atlas-warning'
      email_configs:
      - to: 'platform@astralturf.com'
        subject: '[Atlas Warning] {{ .GroupLabels.alertname }}'
      slack_configs:
      - api_url: '${SLACK_WEBHOOK_URL}'
        channel: '#monitoring'
        title: '⚠️ Warning: {{ .GroupLabels.alertname }}'

    - name: 'atlas-platform-team'
      email_configs:
      - to: 'platform@astralturf.com'
      slack_configs:
      - api_url: '${SLACK_WEBHOOK_URL}'
        channel: '#platform'

    - name: 'atlas-product-team'
      email_configs:
      - to: 'product@astralturf.com'
      slack_configs:
      - api_url: '${SLACK_WEBHOOK_URL}'
        channel: '#product'

    inhibit_rules:
    - source_match:
        severity: 'critical'
      target_match:
        severity: 'warning'
      equal: ['alertname', 'service']
---
# Loki for Log Aggregation
apiVersion: apps/v1
kind: Deployment
metadata:
  name: atlas-loki
  namespace: atlas-monitoring
  labels:
    app: loki
    atlas.monitoring.component: logging
spec:
  replicas: 1
  selector:
    matchLabels:
      app: loki
  template:
    metadata:
      labels:
        app: loki
    spec:
      containers:
        - name: loki
          image: grafana/loki:latest
          args:
            - -config.file=/etc/loki/config.yml
          ports:
            - containerPort: 3100
          volumeMounts:
            - name: loki-config
              mountPath: /etc/loki
            - name: loki-storage
              mountPath: /loki
          resources:
            requests:
              memory: '512Mi'
              cpu: '250m'
            limits:
              memory: '1Gi'
              cpu: '500m'
          livenessProbe:
            httpGet:
              path: /ready
              port: 3100
            initialDelaySeconds: 45
            periodSeconds: 10
          readinessProbe:
            httpGet:
              path: /ready
              port: 3100
            initialDelaySeconds: 45
            periodSeconds: 10
      volumes:
        - name: loki-config
          configMap:
            name: atlas-loki-config
        - name: loki-storage
          persistentVolumeClaim:
            claimName: loki-storage
---
# Atlas Custom Metrics Exporter
apiVersion: apps/v1
kind: Deployment
metadata:
  name: atlas-metrics-exporter
  namespace: atlas-monitoring
  labels:
    app: atlas-metrics-exporter
    atlas.monitoring.component: custom-metrics
spec:
  replicas: 1
  selector:
    matchLabels:
      app: atlas-metrics-exporter
  template:
    metadata:
      labels:
        app: atlas-metrics-exporter
    spec:
      containers:
        - name: metrics-exporter
          image: atlas/metrics-exporter:latest
          ports:
            - containerPort: 8080
          env:
            - name: METRICS_PORT
              value: '8080'
            - name: METRICS_PATH
              value: '/metrics'
            - name: DATABASE_URL
              valueFrom:
                secretKeyRef:
                  name: database-secrets
                  key: url
          resources:
            requests:
              memory: '128Mi'
              cpu: '100m'
            limits:
              memory: '256Mi'
              cpu: '200m'
          livenessProbe:
            httpGet:
              path: /health
              port: 8080
            initialDelaySeconds: 30
            periodSeconds: 10
          readinessProbe:
            httpGet:
              path: /health
              port: 8080
            initialDelaySeconds: 5
            periodSeconds: 5
---
# Storage for monitoring components
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: prometheus-storage
  namespace: atlas-monitoring
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 50Gi
  storageClassName: fast-ssd
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: grafana-storage
  namespace: atlas-monitoring
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi
  storageClassName: fast-ssd
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: alertmanager-storage
  namespace: atlas-monitoring
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 5Gi
  storageClassName: fast-ssd
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: loki-storage
  namespace: atlas-monitoring
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 20Gi
  storageClassName: fast-ssd
