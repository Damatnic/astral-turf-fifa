# ==================================================================
# QUANTUM'S SRE RUNBOOKS & OPERATIONAL DOCUMENTATION
# Complete operational procedures for 99.99% uptime
# ==================================================================

apiVersion: v1
kind: ConfigMap
metadata:
  name: sre-runbooks
  namespace: astral-turf
  labels:
    app.kubernetes.io/name: astral-turf
    app.kubernetes.io/component: sre-documentation
data:
  incident-response.md: |
    # Astral Turf Incident Response Runbook

    ## üö® Critical Incident Response Procedure

    ### Severity Levels
    - **P0 (Critical)**: Complete service outage, data loss, security breach
    - **P1 (High)**: Major functionality impacted, performance severely degraded
    - **P2 (Medium)**: Some functionality impacted, workarounds available
    - **P3 (Low)**: Minor issues, cosmetic problems

    ### Immediate Response (Within 5 minutes)

    #### 1. Alert Acknowledgment
    ```bash
    # Acknowledge in PagerDuty
    pd-cli incident ack --incident-id <INCIDENT_ID>

    # Join incident channel
    slack-cli join-channel #incident-<INCIDENT_ID>
    ```

    #### 2. Initial Assessment
    ```bash
    # Check overall system health
    kubectl get pods -A | grep -v Running

    # Check service endpoints
    curl -f https://app.astral-turf.com/health
    curl -f https://api.astral-turf.com/health

    # Review recent deployments
    kubectl rollout history deployment/astral-turf-app -n astral-turf

    # Check error rates
    curl -s "http://prometheus:9090/api/v1/query?query=rate(http_requests_total{code=~\"5..\"}[5m])"
    ```

    #### 3. Emergency Rollback (if recent deployment)
    ```bash
    # Rollback to previous version
    kubectl rollout undo deployment/astral-turf-app -n astral-turf

    # Verify rollback
    kubectl rollout status deployment/astral-turf-app -n astral-turf

    # Test health after rollback
    curl -f https://app.astral-turf.com/health
    ```

    ### Database Issues

    #### Connection Pool Exhaustion
    ```bash
    # Check connection pool metrics
    kubectl exec -it $(kubectl get pods -l app=postgresql -o name | head -1) -- \
      psql -U astral -d astral_turf -c "SELECT * FROM pg_stat_activity;"

    # Kill long-running queries
    kubectl exec -it $(kubectl get pods -l app=postgresql -o name | head -1) -- \
      psql -U astral -d astral_turf -c "SELECT pg_terminate_backend(pid) FROM pg_stat_activity WHERE state = 'active' AND query_start < now() - interval '10 minutes';"

    # Scale up database connections
    kubectl patch deployment astral-turf-app -n astral-turf -p '{"spec":{"template":{"spec":{"containers":[{"name":"astral-turf","env":[{"name":"DATABASE_POOL_SIZE","value":"50"}]}]}}}}'
    ```

    #### Database Performance Issues
    ```bash
    # Check slow queries
    kubectl exec -it $(kubectl get pods -l app=postgresql -o name | head -1) -- \
      psql -U astral -d astral_turf -c "SELECT query, mean_exec_time, calls FROM pg_stat_statements ORDER BY mean_exec_time DESC LIMIT 10;"

    # Check database locks
    kubectl exec -it $(kubectl get pods -l app=postgresql -o name | head -1) -- \
      psql -U astral -d astral_turf -c "SELECT * FROM pg_locks WHERE NOT granted;"

    # Analyze table sizes
    kubectl exec -it $(kubectl get pods -l app=postgresql -o name | head -1) -- \
      psql -U astral -d astral_turf -c "SELECT schemaname,tablename,attname,n_distinct,correlation FROM pg_stats WHERE schemaname='public';"
    ```

    ### Redis Cache Issues

    #### Memory Issues
    ```bash
    # Check Redis memory usage
    kubectl exec -it $(kubectl get pods -l app=redis -o name | head -1) -- \
      redis-cli info memory

    # Clear cache if necessary (EMERGENCY ONLY)
    kubectl exec -it $(kubectl get pods -l app=redis -o name | head -1) -- \
      redis-cli flushdb

    # Check Redis slow log
    kubectl exec -it $(kubectl get pods -l app=redis -o name | head -1) -- \
      redis-cli slowlog get 10
    ```

    ### Application Performance Issues

    #### High CPU/Memory Usage
    ```bash
    # Check resource usage
    kubectl top pods -n astral-turf

    # Scale up immediately
    kubectl scale deployment astral-turf-app --replicas=20 -n astral-turf

    # Check if HPA is working
    kubectl get hpa -n astral-turf

    # Force HPA scaling
    kubectl patch hpa astral-turf-hpa -n astral-turf -p '{"spec":{"minReplicas":10}}'
    ```

    #### WebSocket Connection Issues
    ```bash
    # Check WebSocket connections
    kubectl exec -it $(kubectl get pods -l app.kubernetes.io/name=astral-turf -o name | head -1) -n astral-turf -- \
      ss -tuln | grep :3000

    # Check nginx proxy settings
    kubectl logs $(kubectl get pods -l app.kubernetes.io/name=nginx -o name | head -1) -n astral-turf

    # Test WebSocket directly
    wscat -c wss://app.astral-turf.com/ws
    ```

    ### Post-Incident Actions

    #### 1. Service Restoration Verification
    ```bash
    # Run comprehensive health checks
    curl -f https://app.astral-turf.com/health
    curl -f https://api.astral-turf.com/health

    # Check all critical user journeys
    curl -f https://api.astral-turf.com/api/tactical-boards
    curl -f https://api.astral-turf.com/api/auth/validate

    # Verify WebSocket functionality
    wscat -c wss://app.astral-turf.com/ws -x '{"type":"ping"}'
    ```

    #### 2. Incident Documentation
    ```yaml
    incident_report:
      incident_id: "INC-YYYY-MM-DD-###"
      severity: "P0/P1/P2/P3"
      start_time: "2024-XX-XX XX:XX:XX UTC"
      end_time: "2024-XX-XX XX:XX:XX UTC"
      duration: "XX minutes"
      affected_services: ["tactical-boards", "user-auth", "real-time-collaboration"]
      root_cause: "Description of the root cause"
      impact: "Description of user impact"
      resolution: "Steps taken to resolve"
      prevention_measures: "Actions to prevent recurrence"
    ```

  disaster-recovery.md: |
    # Disaster Recovery Procedures

    ## üîÑ Multi-Region Failover

    ### Automatic Failover Triggers
    - Primary region health check failures > 3 consecutive
    - Database connection failures > 5 minutes
    - Error rate > 1% for > 10 minutes
    - Response time P99 > 5 seconds for > 5 minutes

    ### Manual Failover Procedure

    #### 1. Assess Primary Region Status
    ```bash
    # Check primary region health
    aws --region us-east-1 ecs describe-clusters --cluster astral-turf-production

    # Check database availability
    aws --region us-east-1 rds describe-db-instances --db-instance-identifier astral-turf-prod

    # Check load balancer health
    aws --region us-east-1 elbv2 describe-target-health --target-group-arn <TARGET_GROUP_ARN>
    ```

    #### 2. Initiate Failover to Secondary Region
    ```bash
    # Update Route53 DNS to secondary region
    aws route53 change-resource-record-sets --hosted-zone-id Z123456789 --change-batch '{
      "Changes": [{
        "Action": "UPSERT",
        "ResourceRecordSet": {
          "Name": "app.astral-turf.com",
          "Type": "CNAME",
          "TTL": 60,
          "ResourceRecords": [{"Value": "us-west-2-lb.astral-turf.com"}]
        }
      }]
    }'

    # Update API endpoint
    aws route53 change-resource-record-sets --hosted-zone-id Z123456789 --change-batch '{
      "Changes": [{
        "Action": "UPSERT",
        "ResourceRecordSet": {
          "Name": "api.astral-turf.com",
          "Type": "CNAME",
          "TTL": 60,
          "ResourceRecords": [{"Value": "us-west-2-api.astral-turf.com"}]
        }
      }]
    }'
    ```

    #### 3. Database Failover
    ```bash
    # Promote read replica to primary
    aws --region us-west-2 rds promote-read-replica --db-instance-identifier astral-turf-prod-west-replica

    # Update application configuration
    kubectl patch secret astral-turf-secrets -n astral-turf -p '{"data":{"database-url":"<BASE64_ENCODED_WEST_DB_URL>"}}'

    # Restart application pods
    kubectl rollout restart deployment/astral-turf-app -n astral-turf
    ```

    #### 4. Verify Secondary Region Operation
    ```bash
    # Wait for DNS propagation
    sleep 300

    # Test endpoints
    curl -f https://app.astral-turf.com/health
    curl -f https://api.astral-turf.com/health

    # Verify database connectivity
    kubectl exec -it $(kubectl get pods -l app.kubernetes.io/name=astral-turf -o name | head -1) -n astral-turf -- \
      node -e "console.log('DB connection test:', require('./db-test.js'))"
    ```

    ## üì¶ Data Recovery Procedures

    ### Database Point-in-Time Recovery
    ```bash
    # Restore database to specific point in time
    aws rds restore-db-instance-to-point-in-time \
      --source-db-instance-identifier astral-turf-prod \
      --target-db-instance-identifier astral-turf-recovery-$(date +%Y%m%d%H%M) \
      --restore-time 2024-XX-XXTXX:XX:XX.000Z

    # Wait for restoration
    aws rds wait db-instance-available --db-instance-identifier astral-turf-recovery-$(date +%Y%m%d%H%M)

    # Test restored database
    psql -h astral-turf-recovery-xxx.amazonaws.com -U astral -d astral_turf -c "SELECT COUNT(*) FROM tactical_boards;"
    ```

    ### File System Recovery
    ```bash
    # Restore from S3 backup
    aws s3 sync s3://astral-turf-disaster-recovery/latest/ /tmp/recovery/

    # Extract and verify backup
    cd /tmp/recovery
    tar -xzf application-data-$(date +%Y%m%d).tar.gz

    # Restore to Kubernetes PVC
    kubectl cp /tmp/recovery/app-data/ astral-turf-app-xxx:/app/data/
    ```

  performance-optimization.md: |
    # Performance Optimization Runbook

    ## üöÄ Performance Tuning Procedures

    ### Database Performance Optimization

    #### Query Optimization
    ```sql
    -- Identify slow queries
    SELECT query, mean_exec_time, calls, total_exec_time 
    FROM pg_stat_statements 
    ORDER BY mean_exec_time DESC 
    LIMIT 20;

    -- Check index usage
    SELECT schemaname, tablename, attname, n_distinct, correlation 
    FROM pg_stats 
    WHERE schemaname = 'public' 
    ORDER BY n_distinct DESC;

    -- Create performance indexes
    CREATE INDEX CONCURRENTLY idx_tactical_boards_user_created 
    ON tactical_boards(user_id, created_at) 
    WHERE deleted_at IS NULL;

    CREATE INDEX CONCURRENTLY idx_collaboration_sessions_active 
    ON collaboration_sessions(board_id, updated_at) 
    WHERE status = 'active';
    ```

    #### Connection Pool Tuning
    ```bash
    # Optimize connection pool settings
    kubectl patch configmap astral-turf-config -n astral-turf -p '{
      "data": {
        "DATABASE_POOL_SIZE": "20",
        "DATABASE_POOL_MAX": "50",
        "DATABASE_POOL_IDLE_TIMEOUT": "30000",
        "DATABASE_POOL_CONNECTION_TIMEOUT": "10000"
      }
    }'

    # Restart application to apply changes
    kubectl rollout restart deployment/astral-turf-app -n astral-turf
    ```

    ### Redis Performance Optimization

    #### Memory Optimization
    ```bash
    # Configure Redis memory settings
    kubectl exec -it $(kubectl get pods -l app=redis -o name | head -1) -- \
      redis-cli config set maxmemory-policy allkeys-lru

    kubectl exec -it $(kubectl get pods -l app=redis -o name | head -1) -- \
      redis-cli config set maxmemory 4gb

    # Optimize key expiration
    kubectl exec -it $(kubectl get pods -l app=redis -o name | head -1) -- \
      redis-cli config set timeout 300
    ```

    ### Application Performance Tuning

    #### Node.js Optimization
    ```bash
    # Update application environment variables
    kubectl patch deployment astral-turf-app -n astral-turf -p '{
      "spec": {
        "template": {
          "spec": {
            "containers": [{
              "name": "astral-turf",
              "env": [
                {"name": "NODE_ENV", "value": "production"},
                {"name": "UV_THREADPOOL_SIZE", "value": "16"},
                {"name": "NODE_OPTIONS", "value": "--max-old-space-size=2048"},
                {"name": "WORKER_THREADS", "value": "4"}
              ]
            }]
          }
        }
      }
    }'
    ```

    #### Kubernetes Resource Optimization
    ```bash
    # Optimize resource requests and limits
    kubectl patch deployment astral-turf-app -n astral-turf -p '{
      "spec": {
        "template": {
          "spec": {
            "containers": [{
              "name": "astral-turf",
              "resources": {
                "requests": {
                  "cpu": "500m",
                  "memory": "1Gi"
                },
                "limits": {
                  "cpu": "2000m",
                  "memory": "4Gi"
                }
              }
            }]
          }
        }
      }
    }'

    # Update HPA for better scaling
    kubectl patch hpa astral-turf-hpa -n astral-turf -p '{
      "spec": {
        "behavior": {
          "scaleUp": {
            "stabilizationWindowSeconds": 30,
            "policies": [
              {"type": "Percent", "value": 100, "periodSeconds": 15},
              {"type": "Pods", "value": 20, "periodSeconds": 15}
            ]
          }
        }
      }
    }'
    ```

  security-procedures.md: |
    # Security Incident Response

    ## üîí Security Breach Response

    ### Immediate Actions (Within 5 minutes)

    #### 1. Isolate Affected Systems
    ```bash
    # Block suspicious IP addresses
    kubectl apply -f - <<EOF
    apiVersion: networking.k8s.io/v1
    kind: NetworkPolicy
    metadata:
      name: emergency-block-suspicious-ips
      namespace: astral-turf
    spec:
      podSelector: {}
      policyTypes:
      - Ingress
      ingress:
      - from:
        - ipBlock:
            cidr: 0.0.0.0/0
            except:
            - SUSPICIOUS_IP_1/32
            - SUSPICIOUS_IP_2/32
    EOF

    # Scale down affected services if necessary
    kubectl scale deployment astral-turf-app --replicas=0 -n astral-turf
    ```

    #### 2. Evidence Collection
    ```bash
    # Collect logs from affected pods
    kubectl logs -l app.kubernetes.io/name=astral-turf -n astral-turf --since=1h > security-incident-logs.txt

    # Collect Falco security events
    kubectl logs -l app.kubernetes.io/name=falco -n security-system --since=1h > falco-security-events.txt

    # Export network policies and security configs
    kubectl get networkpolicies,securitypolicies -A -o yaml > security-configs-backup.yaml
    ```

    #### 3. Rotate Credentials
    ```bash
    # Generate new JWT secret
    NEW_JWT_SECRET=$(openssl rand -base64 32)
    kubectl patch secret astral-turf-secrets -n astral-turf -p "{\"data\":{\"jwt-secret\":\"$(echo -n $NEW_JWT_SECRET | base64)\"}}"

    # Rotate database password
    NEW_DB_PASSWORD=$(openssl rand -base64 16)
    kubectl patch secret astral-turf-secrets -n astral-turf -p "{\"data\":{\"database-password\":\"$(echo -n $NEW_DB_PASSWORD | base64)\"}}"

    # Update database password
    kubectl exec -it $(kubectl get pods -l app=postgresql -o name | head -1) -- \
      psql -U postgres -c "ALTER USER astral PASSWORD '$NEW_DB_PASSWORD';"
    ```

    ### Investigation Procedures

    #### 1. Analyze Security Logs
    ```bash
    # Search for authentication failures
    grep -i "authentication failed\|unauthorized\|access denied" security-incident-logs.txt

    # Check for privilege escalation attempts
    grep -i "privilege\|escalation\|sudo\|root" falco-security-events.txt

    # Analyze network connections
    kubectl exec -it $(kubectl get pods -l app.kubernetes.io/name=astral-turf -o name | head -1) -n astral-turf -- \
      netstat -tulpn | grep ESTABLISHED
    ```

    #### 2. Vulnerability Assessment
    ```bash
    # Run security scan on containers
    trivy image astral-turf:latest --severity HIGH,CRITICAL

    # Check for exposed secrets
    kubectl get secrets -A -o yaml | grep -E "password|token|key" | grep -v "kubernetes.io"

    # Verify RBAC permissions
    kubectl auth can-i --list --as=system:serviceaccount:astral-turf:astral-turf-sa
    ```

    ## üõ°Ô∏è Security Hardening

    ### Network Security
    ```bash
    # Implement strict network policies
    kubectl apply -f - <<EOF
    apiVersion: networking.k8s.io/v1
    kind: NetworkPolicy
    metadata:
      name: deny-all-default
      namespace: astral-turf
    spec:
      podSelector: {}
      policyTypes:
      - Ingress
      - Egress
    EOF

    # Enable service mesh security
    kubectl label namespace astral-turf istio-injection=enabled
    kubectl apply -f - <<EOF
    apiVersion: security.istio.io/v1beta1
    kind: PeerAuthentication
    metadata:
      name: default
      namespace: astral-turf
    spec:
      mtls:
        mode: STRICT
    EOF
    ```

  monitoring-procedures.md: |
    # Monitoring & Alerting Runbook

    ## üìä Metrics Investigation

    ### Application Metrics
    ```bash
    # Check application health metrics
    curl -s "http://prometheus:9090/api/v1/query?query=up{job=\"astral-turf-app\"}"

    # Check response time trends
    curl -s "http://prometheus:9090/api/v1/query?query=histogram_quantile(0.99, rate(http_request_duration_seconds_bucket[5m]))"

    # Check error rates
    curl -s "http://prometheus:9090/api/v1/query?query=rate(http_requests_total{code=~\"5..\"}[5m])"

    # Check active user sessions
    curl -s "http://prometheus:9090/api/v1/query?query=active_user_sessions"
    ```

    ### Infrastructure Metrics
    ```bash
    # Check cluster resource usage
    kubectl top nodes
    kubectl top pods -A --sort-by=cpu

    # Check storage usage
    df -h
    kubectl get pv,pvc -A

    # Check network connectivity
    kubectl exec -it $(kubectl get pods -l app.kubernetes.io/name=astral-turf -o name | head -1) -n astral-turf -- \
      ping -c 3 google.com
    ```

    ### Database Metrics
    ```bash
    # Check database performance
    kubectl exec -it $(kubectl get pods -l app=postgresql -o name | head -1) -- \
      psql -U astral -d astral_turf -c "
        SELECT 
          datname,
          numbackends,
          xact_commit,
          xact_rollback,
          blks_read,
          blks_hit,
          tup_returned,
          tup_fetched,
          tup_inserted,
          tup_updated,
          tup_deleted
        FROM pg_stat_database 
        WHERE datname = 'astral_turf';
      "

    # Check connection pool status
    kubectl exec -it $(kubectl get pods -l app.kubernetes.io/name=astral-turf -o name | head -1) -n astral-turf -- \
      curl localhost:3000/metrics | grep database_pool
    ```

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: sre-scripts
  namespace: astral-turf
  labels:
    app.kubernetes.io/name: astral-turf
    app.kubernetes.io/component: sre-scripts
data:
  health-check.sh: |
    #!/bin/bash
    # Comprehensive health check script

    echo "üîç Astral Turf Health Check - $(date)"
    echo "=================================="

    # Application health
    echo "üì± Application Health:"
    curl -f -s https://app.astral-turf.com/health && echo "‚úÖ App healthy" || echo "‚ùå App unhealthy"
    curl -f -s https://api.astral-turf.com/health && echo "‚úÖ API healthy" || echo "‚ùå API unhealthy"

    # Database health
    echo -e "\nüóÑÔ∏è  Database Health:"
    kubectl exec -it $(kubectl get pods -l app=postgresql -o name | head -1) -- \
      psql -U astral -d astral_turf -c "SELECT 1;" > /dev/null 2>&1 && \
      echo "‚úÖ Database healthy" || echo "‚ùå Database unhealthy"

    # Redis health
    echo -e "\nüîÑ Cache Health:"
    kubectl exec -it $(kubectl get pods -l app=redis -o name | head -1) -- \
      redis-cli ping > /dev/null 2>&1 && \
      echo "‚úÖ Redis healthy" || echo "‚ùå Redis unhealthy"

    # Pod status
    echo -e "\nüèÉ Pod Status:"
    kubectl get pods -n astral-turf | grep -v Running | wc -l | xargs -I {} echo "Non-running pods: {}"

    # Resource usage
    echo -e "\nüíª Resource Usage:"
    kubectl top pods -n astral-turf --no-headers | awk '{cpu+=$2; mem+=$3} END {print "Total CPU:", cpu"m", "Total Memory:", mem"Mi"}'

    echo -e "\nüéâ Health check completed"

  performance-test.sh: |
    #!/bin/bash
    # Quick performance test script

    echo "üöÄ Astral Turf Performance Test - $(date)"
    echo "========================================="

    # Response time test
    echo "‚è±Ô∏è  Response Time Test:"
    time curl -s https://app.astral-turf.com > /dev/null

    # Load test
    echo -e "\nüìà Load Test (50 concurrent users):"
    ab -n 1000 -c 50 https://app.astral-turf.com/ | grep "Requests per second\|Time per request"

    # WebSocket test
    echo -e "\nüîå WebSocket Test:"
    timeout 10s wscat -c wss://app.astral-turf.com/ws -x '{"type":"ping"}' && \
      echo "‚úÖ WebSocket working" || echo "‚ùå WebSocket failed"

    echo -e "\nüéØ Performance test completed"

  backup-verification.sh: |
    #!/bin/bash
    # Backup verification script

    echo "üíæ Backup Verification - $(date)"
    echo "==============================="

    # Check latest database backup
    echo "üóÑÔ∏è  Database Backup:"
    LATEST_DB_BACKUP=$(aws s3 ls s3://astral-turf-disaster-recovery/database/ | sort | tail -n 1 | awk '{print $4}')
    echo "Latest backup: $LATEST_DB_BACKUP"

    # Verify backup integrity
    aws s3 cp s3://astral-turf-disaster-recovery/database/$LATEST_DB_BACKUP /tmp/test-backup.sql.gz
    gunzip -t /tmp/test-backup.sql.gz && \
      echo "‚úÖ Backup integrity verified" || echo "‚ùå Backup corrupted"

    # Check backup age
    BACKUP_AGE=$(aws s3api head-object --bucket astral-turf-disaster-recovery --key database/$LATEST_DB_BACKUP --query 'LastModified' --output text)
    echo "Backup age: $(date -d "$BACKUP_AGE" '+%H hours %M minutes')"

    # Check application state backup
    echo -e "\nüì¶ Application State Backup:"
    LATEST_STATE_BACKUP=$(aws s3 ls s3://astral-turf-disaster-recovery/k8s-state/ | sort | tail -n 1 | awk '{print $4}')
    echo "Latest state backup: $LATEST_STATE_BACKUP"

    echo -e "\n‚úÖ Backup verification completed"

---
apiVersion: batch/v1
kind: CronJob
metadata:
  name: automated-health-checks
  namespace: astral-turf
  labels:
    app.kubernetes.io/name: health-checker
    app.kubernetes.io/component: monitoring
spec:
  schedule: '*/5 * * * *' # Every 5 minutes
  concurrencyPolicy: Forbid
  successfulJobsHistoryLimit: 3
  failedJobsHistoryLimit: 3
  jobTemplate:
    spec:
      template:
        metadata:
          labels:
            app.kubernetes.io/name: health-check-job
        spec:
          restartPolicy: OnFailure
          containers:
            - name: health-checker
              image: alpine/curl:latest
              imagePullPolicy: IfNotPresent
              resources:
                requests:
                  cpu: 50m
                  memory: 64Mi
                limits:
                  cpu: 100m
                  memory: 128Mi
              command:
                - /bin/sh
                - -c
                - |
                  /scripts/health-check.sh

                  # Report to monitoring
                  if [ $? -eq 0 ]; then
                    curl -X POST http://prometheus-pushgateway:9091/metrics/job/health-check/instance/automated \
                      -d 'health_check_status 1'
                  else
                    curl -X POST http://prometheus-pushgateway:9091/metrics/job/health-check/instance/automated \
                      -d 'health_check_status 0'
                  fi
              volumeMounts:
                - name: scripts
                  mountPath: /scripts
                  readOnly: true
          volumes:
            - name: scripts
              configMap:
                name: sre-scripts
                defaultMode: 0755
