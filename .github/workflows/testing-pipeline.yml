name: ğŸ§ª Comprehensive Testing Pipeline

on:
  push:
    branches: [main, develop, master]
  pull_request:
    types: [opened, synchronize, reopened]
  schedule:
    # Run full test suite nightly at 2 AM UTC
    - cron: '0 2 * * *'

env:
  NODE_VERSION: '18'
  CACHE_DEPENDENCIES_PATH: |
    node_modules
    ~/.npm
  
jobs:
  # Job 1: Code Quality & Fast Tests
  quality-gate:
    name: ğŸ¯ Quality Gate
    runs-on: ubuntu-latest
    timeout-minutes: 15
    outputs:
      should-run-full-suite: ${{ steps.changes.outputs.src }}
    
    steps:
      - name: ğŸ“¥ Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: ğŸ” Detect changes
        uses: dorny/paths-filter@v2
        id: changes
        with:
          filters: |
            src:
              - 'src/**'
              - '**/*.test.*'
              - '**/*.spec.*'
              - 'package*.json'
              - 'vite.config.ts'
              - 'tsconfig.json'

      - name: âš¡ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: ğŸ“¦ Install dependencies
        run: npm ci --prefer-offline --no-audit

      - name: ğŸ”§ TypeScript check
        run: npm run type-check

      - name: ğŸ¨ Lint check
        run: npm run lint

      - name: ğŸ’… Format check
        run: npm run format:check

      - name: âš¡ Fast unit tests
        run: npm run test:run -- --reporter=verbose --run --coverage=false
        timeout-minutes: 5

  # Job 2: Comprehensive Unit & Integration Tests
  unit-integration-tests:
    name: ğŸ§ª Unit & Integration Tests
    runs-on: ubuntu-latest
    needs: quality-gate
    if: needs.quality-gate.outputs.should-run-full-suite == 'true'
    timeout-minutes: 20
    strategy:
      matrix:
        test-group: ['unit', 'integration', 'services', 'components']
    
    steps:
      - name: ğŸ“¥ Checkout code
        uses: actions/checkout@v4

      - name: âš¡ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: ğŸ“¦ Install dependencies
        run: npm ci --prefer-offline --no-audit

      - name: ğŸ§ª Run ${{ matrix.test-group }} tests
        run: |
          case "${{ matrix.test-group }}" in
            "unit")
              npm run test:run -- --reporter=verbose src/__tests__/components src/__tests__/hooks src/__tests__/utils
              ;;
            "integration") 
              npm run test:run -- --reporter=verbose src/__tests__/integration
              ;;
            "services")
              npm run test:run -- --reporter=verbose src/__tests__/services
              ;;
            "components")
              npm run test:run -- --reporter=verbose src/__tests__/context
              ;;
          esac

      - name: ğŸ“Š Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: test-results-${{ matrix.test-group }}
          path: |
            coverage/
            test-results.xml
          retention-days: 7

  # Job 3: Advanced Testing (Visual, A11y, Performance)
  advanced-testing:
    name: ğŸš€ Advanced Testing Suite
    runs-on: ubuntu-latest
    needs: quality-gate
    if: needs.quality-gate.outputs.should-run-full-suite == 'true'
    timeout-minutes: 25
    
    steps:
      - name: ğŸ“¥ Checkout code
        uses: actions/checkout@v4

      - name: âš¡ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: ğŸ“¦ Install dependencies
        run: npm ci --prefer-offline --no-audit

      - name: ğŸ¨ Visual Regression Tests
        run: npm run test:run -- --reporter=verbose src/__tests__/visual
        continue-on-error: true

      - name: â™¿ Accessibility Tests
        run: npm run test:run -- --reporter=verbose src/__tests__/accessibility
        continue-on-error: true

      - name: âš¡ Performance Tests
        run: npm run test:run -- --reporter=verbose src/__tests__/performance
        continue-on-error: true

      - name: ğŸ“Š Upload advanced test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: advanced-test-results
          path: |
            visual-diff/
            a11y-reports/
            performance-reports/
          retention-days: 7

  # Job 4: End-to-End Tests
  e2e-tests:
    name: ğŸŒ E2E Tests
    runs-on: ubuntu-latest
    needs: [quality-gate, unit-integration-tests]
    if: needs.quality-gate.outputs.should-run-full-suite == 'true'
    timeout-minutes: 30
    
    steps:
      - name: ğŸ“¥ Checkout code
        uses: actions/checkout@v4

      - name: âš¡ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: ğŸ“¦ Install dependencies
        run: npm ci --prefer-offline --no-audit

      - name: ğŸ­ Install Playwright
        run: npx playwright install --with-deps

      - name: ğŸ—ï¸ Build application
        run: npm run build

      - name: ğŸŒ Run E2E tests
        run: npm run e2e
        env:
          CI: true

      - name: ğŸ“Š Upload E2E results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: e2e-results
          path: |
            playwright-report/
            test-results/
          retention-days: 7

  # Job 5: Coverage Analysis
  coverage-analysis:
    name: ğŸ“Š Coverage Analysis
    runs-on: ubuntu-latest
    needs: [unit-integration-tests]
    if: always() && needs.quality-gate.outputs.should-run-full-suite == 'true'
    timeout-minutes: 15
    
    steps:
      - name: ğŸ“¥ Checkout code
        uses: actions/checkout@v4

      - name: âš¡ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: ğŸ“¦ Install dependencies
        run: npm ci --prefer-offline --no-audit

      - name: ğŸ“Š Generate coverage report
        run: npm run test:coverage -- --reporter=verbose

      - name: ğŸ“ˆ Upload coverage to Codecov
        uses: codecov/codecov-action@v3
        with:
          files: ./coverage/lcov.info
          fail_ci_if_error: false
          verbose: true

      - name: ğŸ¯ Coverage requirements check
        run: |
          # Check coverage thresholds
          node -e "
          const fs = require('fs');
          const coverage = JSON.parse(fs.readFileSync('coverage/coverage-summary.json'));
          const thresholds = {
            statements: 90,
            branches: 85,
            functions: 90,
            lines: 90
          };
          
          let failed = false;
          Object.entries(thresholds).forEach(([key, threshold]) => {
            const actual = coverage.total[key].pct;
            if (actual < threshold) {
              console.error(\`âŒ \${key} coverage \${actual}% is below threshold \${threshold}%\`);
              failed = true;
            } else {
              console.log(\`âœ… \${key} coverage \${actual}% meets threshold \${threshold}%\`);
            }
          });
          
          if (failed) process.exit(1);
          "

  # Job 6: Mutation Testing (Weekly)
  mutation-testing:
    name: ğŸ§¬ Mutation Testing
    runs-on: ubuntu-latest
    needs: quality-gate
    if: github.event_name == 'schedule' || contains(github.event.head_commit.message, '[mutation]')
    timeout-minutes: 60
    
    steps:
      - name: ğŸ“¥ Checkout code
        uses: actions/checkout@v4

      - name: âš¡ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: ğŸ“¦ Install dependencies
        run: |
          npm ci --prefer-offline --no-audit
          npm install -g stryker-cli @stryker-mutator/core @stryker-mutator/vitest-runner

      - name: ğŸ§¬ Run mutation tests
        run: stryker run src/__tests__/mutation/mutation-testing.config.js
        continue-on-error: true

      - name: ğŸ“Š Upload mutation report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: mutation-testing-report
          path: reports/mutation/
          retention-days: 30

  # Job 7: Performance Benchmarking
  performance-benchmarking:
    name: âš¡ Performance Benchmarking
    runs-on: ubuntu-latest
    needs: quality-gate
    if: github.event_name == 'pull_request' || github.event_name == 'schedule'
    timeout-minutes: 20
    
    steps:
      - name: ğŸ“¥ Checkout code
        uses: actions/checkout@v4

      - name: âš¡ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: ğŸ“¦ Install dependencies
        run: npm ci --prefer-offline --no-audit

      - name: ğŸ—ï¸ Build for performance testing
        run: npm run build

      - name: âš¡ Run performance benchmarks
        run: |
          # Bundle size analysis
          npm run analyze
          
          # Runtime performance tests
          npm run test:run -- src/__tests__/performance --reporter=verbose

      - name: ğŸ“Š Performance regression check
        run: |
          echo "ğŸ¯ Performance Benchmarks:"
          echo "Bundle size should be < 2MB"
          echo "Initial load should be < 3s"
          echo "Component render should be < 100ms"

  # Job 8: Security Testing
  security-testing:
    name: ğŸ›¡ï¸ Security Testing
    runs-on: ubuntu-latest
    needs: quality-gate
    timeout-minutes: 15
    
    steps:
      - name: ğŸ“¥ Checkout code
        uses: actions/checkout@v4

      - name: ğŸ›¡ï¸ Run security audit
        run: npm audit --audit-level=moderate

      - name: ğŸ” Dependency vulnerability scan
        uses: actions/dependency-review-action@v3
        if: github.event_name == 'pull_request'

      - name: ğŸ›¡ï¸ CodeQL security analysis
        uses: github/codeql-action/analyze@v2
        with:
          languages: javascript
        continue-on-error: true

  # Job 9: Test Results Summary
  test-summary:
    name: ğŸ“‹ Test Results Summary
    runs-on: ubuntu-latest
    needs: [quality-gate, unit-integration-tests, advanced-testing, e2e-tests, coverage-analysis]
    if: always()
    
    steps:
      - name: ğŸ“Š Download all test artifacts
        uses: actions/download-artifact@v4
        with:
          path: ./test-artifacts

      - name: ğŸ“‹ Generate test summary
        run: |
          echo "## ğŸ§ª Test Results Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [[ "${{ needs.quality-gate.result }}" == "success" ]]; then
            echo "âœ… **Quality Gate**: Passed" >> $GITHUB_STEP_SUMMARY
          else
            echo "âŒ **Quality Gate**: Failed" >> $GITHUB_STEP_SUMMARY
          fi
          
          if [[ "${{ needs.unit-integration-tests.result }}" == "success" ]]; then
            echo "âœ… **Unit & Integration Tests**: Passed" >> $GITHUB_STEP_SUMMARY
          else
            echo "âŒ **Unit & Integration Tests**: Failed" >> $GITHUB_STEP_SUMMARY
          fi
          
          if [[ "${{ needs.advanced-testing.result }}" == "success" ]]; then
            echo "âœ… **Advanced Testing**: Passed" >> $GITHUB_STEP_SUMMARY
          else
            echo "âš ï¸ **Advanced Testing**: Some issues detected" >> $GITHUB_STEP_SUMMARY
          fi
          
          if [[ "${{ needs.e2e-tests.result }}" == "success" ]]; then
            echo "âœ… **E2E Tests**: Passed" >> $GITHUB_STEP_SUMMARY
          else
            echo "âŒ **E2E Tests**: Failed" >> $GITHUB_STEP_SUMMARY
          fi
          
          if [[ "${{ needs.coverage-analysis.result }}" == "success" ]]; then
            echo "âœ… **Coverage Requirements**: Met" >> $GITHUB_STEP_SUMMARY
          else
            echo "âŒ **Coverage Requirements**: Not met" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "ğŸ“Š **Detailed reports available in workflow artifacts**" >> $GITHUB_STEP_SUMMARY

      - name: ğŸ’¬ Comment on PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const summary = `## ğŸ§ª Testing Pipeline Results
            
            | Test Suite | Status |
            |------------|--------|
            | Quality Gate | ${{ needs.quality-gate.result == 'success' && 'âœ… Passed' || 'âŒ Failed' }} |
            | Unit & Integration | ${{ needs.unit-integration-tests.result == 'success' && 'âœ… Passed' || 'âŒ Failed' }} |
            | Advanced Testing | ${{ needs.advanced-testing.result == 'success' && 'âœ… Passed' || 'âš ï¸ Issues' }} |
            | E2E Tests | ${{ needs.e2e-tests.result == 'success' && 'âœ… Passed' || 'âŒ Failed' }} |
            | Coverage | ${{ needs.coverage-analysis.result == 'success' && 'âœ… Met' || 'âŒ Below threshold' }} |
            
            ğŸ“Š Detailed reports are available in the [workflow artifacts](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}).
            `;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: summary
            });

# Workflow completion notification
concurrency:
  group: testing-${{ github.ref }}
  cancel-in-progress: true